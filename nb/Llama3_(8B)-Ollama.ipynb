{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/offcool/Fine-Tuning-/blob/main/nb/Llama3_(8B)-Ollama.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGum3hgJpTI-"
      },
      "source": [
        "To run this, press \"*Runtime*\" and press \"*Run all*\" on a **free** Tesla T4 Google Colab instance!\n",
        "<div class=\"align-center\">\n",
        "<a href=\"https://unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "<a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord button.png\" width=\"145\"></a>\n",
        "<a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a></a> Join Discord if you need help + ‚≠ê <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ‚≠ê\n",
        "</div>\n",
        "\n",
        "To install Unsloth your local device, follow [our guide](https://docs.unsloth.ai/get-started/install-and-update). This notebook is licensed [LGPL-3.0](https://github.com/unslothai/notebooks?tab=LGPL-3.0-1-ov-file#readme).\n",
        "\n",
        "You will learn how to do [data prep](#Data), how to [train](#Train), how to [run the model](#Inference), & [how to save it](#Save)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKFG-cIOpTJK"
      },
      "source": [
        "### News"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GxCK0dspTJP"
      },
      "source": [
        "\n",
        "Unsloth's [Docker image](https://hub.docker.com/r/unsloth/unsloth) is here! Start training with no setup & environment issues. [Read our Guide](https://docs.unsloth.ai/new/how-to-train-llms-with-unsloth-and-docker).\n",
        "\n",
        "[gpt-oss RL](https://docs.unsloth.ai/new/gpt-oss-reinforcement-learning) is now supported with the fastest inference & lowest VRAM. Try our [new notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/gpt-oss-(20B)-GRPO.ipynb) which creates kernels!\n",
        "\n",
        "Introducing [Vision](https://docs.unsloth.ai/new/vision-reinforcement-learning-vlm-rl) and [Standby](https://docs.unsloth.ai/basics/memory-efficient-rl) for RL! Train Qwen, Gemma etc. VLMs with GSPO - even faster with less VRAM.\n",
        "\n",
        "Unsloth now supports Text-to-Speech (TTS) models. Read our [guide here](https://docs.unsloth.ai/basics/text-to-speech-tts-fine-tuning).\n",
        "\n",
        "Visit our docs for all our [model uploads](https://docs.unsloth.ai/get-started/all-our-models) and [notebooks](https://docs.unsloth.ai/get-started/unsloth-notebooks).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WM5vMynEpTJQ"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JRoIPCR0pTJR"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os, re\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
        "    import torch; v = re.match(r\"[0-9\\.]{3,}\", str(torch.__version__)).group(0)\n",
        "    xformers = \"xformers==\" + (\"0.0.32.post2\" if v == \"2.8.0\" else \"0.0.29.post3\")\n",
        "    !pip install --no-deps bitsandbytes accelerate {xformers} peft trl triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf \"datasets>=3.4.1,<4.0.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n",
        "    !pip install --no-deps unsloth\n",
        "!pip install transformers==4.56.2\n",
        "!pip install --no-deps trl==0.22.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxZ6LrBqpTJX"
      },
      "source": [
        "### Unsloth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680,
          "referenced_widgets": [
            "267067dafbe94dfdb8870dcfd5e41392",
            "dfb2b0760f9b4fed8a51e9d2ef159625",
            "6764006aa85d4917af731d1353d92494",
            "60ef556b4c7649999c72d428c3d7375c",
            "52ac2792620543e2a26ee32e92666efc",
            "10543dd3a389472195b6ad38736d2ed5",
            "036349c761f549fbb7ed672e86cc4d88",
            "eb268e703a854e1bb2c8cfe8240e696c",
            "50518331691b42e88c03059d64e05b62",
            "1a35ba367c2c4edb88ee4e4d45072d94",
            "de8db97cc3f842fc9c5082736d1c2771",
            "87b012781037424db9b76d612b826308",
            "b5aa226f8d61498c90af693bb5319575",
            "dd4f19f2091d4680ac0bab1480dfac06",
            "d031c0d46b1c44158425a6f30c2220a4",
            "348d31ea3d8248529447d98a7a970277",
            "f8888bfbd41b4b3289d4ea49c4aff06a",
            "b8cbde4b97024b298975a26f07e81df5",
            "8b595eecbbbc4c798885c2049485c0ef",
            "8576200b2f744525be14c81a3ef2860b",
            "4b0df7467aa04a388a186a87e2de81a9",
            "ecccac4498194d6295d10374ea4fab8e",
            "bfe1b2eeb0c94094a7c4336dcc31716a",
            "fea0aa5bcba34af69a533b476613f4ef",
            "83d8ae3a10774f9383dce13834fa6810",
            "29232f5187534e71bc140ae2239500e5",
            "ce353e3f5c5d44ccb4bb1887bb7dad86",
            "72f81401952143509e6ddb44e9aa64bb",
            "5bfa027a7f0b421ab63cd299752fd751",
            "bad196e64e514f178e8b4474493cfbaf",
            "51c60bb5725c48ef9ba686252c4dc9e6",
            "f542ad4b8cb14743b1ccaea4aea03821",
            "8c8077d5bb48489caa6256e17941d7d6",
            "575c04d7da794dbaa0b68b56a07c78cf",
            "261cd71c6bc840cfb5a1ebf38f9ad221",
            "7bb5fe9df041437e80042a27a269ed70",
            "ce6355ed0b1548a288d072faa44e2978",
            "0705a74711a14023a78f855c5df606c1",
            "ce0d31a6c95e4d9dbf11fbd1272973ef",
            "c00ea326da08481788558fb3fa00f166",
            "0618c6fcf8b247beb56b3e0904f1afee",
            "923b54e5354d4813a51b6072ab2b64e7",
            "84a68f8831294380ad61ec2a6aba4717",
            "b15dc6ee8ab14be1952d2c3663a1108f",
            "9c4254c725c34168a182a063155033fe",
            "df89b85749974042bbe1de973e6653ee",
            "77b11be9dfa84d08bb120ed7cfe1f53c",
            "cd6060fbdd784c55bc4b1e956b5f36d3",
            "b7b6b9faa9cf49ca96a06e30b583daee",
            "da60b444b0dd4fe6ae76b73bd790f751",
            "a8129fe72d384c53b900474f33914275",
            "a5a209fbc30b44f0a377f858130c52db",
            "d85ba7cb2c964dafbc54fbc1090da824",
            "da1bf2f2a93847308701555f0cab7aa2",
            "022bb664096d4bd29db4d4ebfe0472f6"
          ]
        },
        "id": "QmUBVEnvCDJv",
        "outputId": "debc314a-bfd5-47ab-9170-350b623c8fe6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:xformers:WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
            "    PyTorch 2.6.0+cu124 with CUDA 1204 (you have 2.9.0+cu126)\n",
            "    Python  3.12.9 (you have 3.12.12)\n",
            "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
            "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
            "  Set XFORMERS_MORE_DETAILS=1 for more details\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========\n",
            "Switching to PyTorch attention since your Xformers is broken.\n",
            "========\n",
            "\n",
            "Unsloth: Xformers was not installed correctly.\n",
            "Please install xformers separately first.\n",
            "Then confirm if it's correctly installed by running:\n",
            "python -m xformers.info\n",
            "\n",
            "Longer error message:\n",
            "xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
            "    PyTorch 2.6.0+cu124 with CUDA 1204 (you have 2.9.0+cu126)\n",
            "    Python  3.12.9 (you have 3.12.12)\n",
            "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
            "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
            "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2025.11.3: Fast Llama patching. Transformers: 4.56.2.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.9.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.5.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = None. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/5.70G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "267067dafbe94dfdb8870dcfd5e41392"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/198 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "87b012781037424db9b76d612b826308"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bfe1b2eeb0c94094a7c4336dcc31716a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "575c04d7da794dbaa0b68b56a07c78cf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9c4254c725c34168a182a063155033fe"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
        "fourbit_models = [\n",
        "    \"unsloth/mistral-7b-v0.3-bnb-4bit\",      # New Mistral v3 2x faster!\n",
        "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
        "    \"unsloth/llama-3-8b-bnb-4bit\",           # Llama-3 15 trillion tokens model 2x faster!\n",
        "    \"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n",
        "    \"unsloth/llama-3-70b-bnb-4bit\",\n",
        "    \"unsloth/Phi-3-mini-4k-instruct\",        # Phi-3 2x faster!\n",
        "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
        "    \"unsloth/mistral-7b-bnb-4bit\",\n",
        "    \"unsloth/gemma-7b-bnb-4bit\",             # Gemma 2.2x faster!\n",
        "] # More models at https://huggingface.co/unsloth\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/llama-3-8b-bnb-4bit\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXd9bTZd1aaL"
      },
      "source": [
        "We now add LoRA adapters so we only need to update 1 to 10% of all parameters!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bZsfBuZDeCL",
        "outputId": "0d9b9534-5a51-4f8f-8941-f338fce51b33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2025.11.3 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vITh0KVJ10qX"
      },
      "source": [
        "<a name=\"Data\"></a>\n",
        "### Data Prep\n",
        "We now use the Alpaca dataset from [vicgalle](https://huggingface.co/datasets/vicgalle/alpaca-gpt4), which is a version of 52K of the original [Alpaca dataset](https://crfm.stanford.edu/2023/03/13/alpaca.html) generated from GPT4. You can replace this code section with your own data prep."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbUSp6z3sHl1",
        "outputId": "ee852424-03e6-48d8-bafc-b4d3716d8bff"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "9ee5b91602d74aee9448bf9ce042eb1b",
            "ab5399b2268e44a9a2f49786fabbfaad",
            "a9854cafd27740d69fd45a8248304d71",
            "3738f99efac6430ca65694f6c0977ff4",
            "93d6a2fd944b4efbac603a7800f38122",
            "76400998973d4ea08bc0e99ecc45869e",
            "8179590eb74148cd88ef441d783b0141",
            "11caea6e2c504bf882e896ed6dbbf810",
            "7b7bd5c149ee40c1895a7cd7020304f1",
            "2af37c7f26a24263b40af49ae782d39d",
            "e584bceda9fc434589f08fde08c85e08"
          ]
        },
        "id": "HvOPfPnet76H",
        "outputId": "904120bc-5fa2-4c3b-d564-2cb0521d3fab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File found at: /content/comprehensive_requirement_dataset_full.json\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ee5b91602d74aee9448bf9ce042eb1b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['conversations', 'instruction', 'input', 'output']\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "import os\n",
        "\n",
        "file_path = \"/content/comprehensive_requirement_dataset_full.json\"\n",
        "\n",
        "if os.path.exists(file_path):\n",
        "    print(f\"File found at: {file_path}\")\n",
        "    dataset = load_dataset(\"json\", data_files=file_path, split=\"train\")\n",
        "    print(dataset.column_names)\n",
        "else:\n",
        "    print(f\"Error: File not found at {file_path}. Please check the path and ensure the file exists.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xg4_dG-m0Cz4"
      },
      "source": [
        "One issue is this dataset has multiple columns. For `Ollama` and `llama.cpp` to function like a custom `ChatGPT` Chatbot, we must only have 2 columns - an `instruction` and an `output` column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTQR4jrDMcJf",
        "outputId": "200b3766-0392-4a5f-c103-833808cf9b73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['conversations', 'instruction', 'input', 'output']\n"
          ]
        }
      ],
      "source": [
        "print(dataset.column_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwEbRFl0Mf3E"
      },
      "source": [
        "To solve this, we shall do the following:\n",
        "* Merge all columns into 1 instruction prompt.\n",
        "* Remember LLMs are text predictors, so we can customize the instruction to anything we like!\n",
        "* Use the `to_sharegpt` function to do this column merging process!\n",
        "\n",
        "For example below in our [Titanic CSV finetuning notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb), we merged multiple columns in 1 prompt:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/unslothai/unsloth/nightly/images/Merge.png\" height=\"100\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w61VJ7rQM8jT"
      },
      "source": [
        "To merge multiple columns into 1, use `merged_prompt`.\n",
        "* Enclose all columns in curly braces `{}`.\n",
        "* Optional text must be enclused in `[[]]`. For example if the column \"Pclass\" is empty, the merging function will not show the text and skp this. This is useful for datasets with missing values.\n",
        "* You can select every column, or a few!\n",
        "* Select the output or target / prediction column in `output_column_name`. For the Alpaca dataset, this will be `output`.\n",
        "\n",
        "To make the finetune handle multiple turns (like in ChatGPT), we have to create a \"fake\" dataset with multiple turns - we use `conversation_extension` to randomnly select some conversations from the dataset, and pack them together into 1 conversation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "jZxeGSeX0CR8",
        "outputId": "58d8a73e-d6dc-4729-c603-03b05a3e397e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Unsloth: Your dataset is probably already in ShareGPT format!",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-224614635.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0munsloth\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_sharegpt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m dataset = to_sharegpt(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmerged_prompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"{instruction}[[\\nYour input is:\\n{input}]]\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/unsloth/chat_templates.py\u001b[0m in \u001b[0;36mto_sharegpt\u001b[0;34m(dataset, merged_prompt, merged_column_name, output_column_name, remove_unused_columns, conversation_extension, random_state)\u001b[0m\n\u001b[1;32m   2464\u001b[0m         \u001b[0mconvo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"conversations\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2465\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2466\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unsloth: Your dataset is probably already in ShareGPT format!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2468\u001b[0m     \u001b[0mpossible_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_optional_prompts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_combined_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_prompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Unsloth: Your dataset is probably already in ShareGPT format!"
          ]
        }
      ],
      "source": [
        "from unsloth import to_sharegpt\n",
        "\n",
        "dataset = to_sharegpt(\n",
        "    dataset,\n",
        "    merged_prompt=\"{instruction}[[\\nYour input is:\\n{input}]]\",\n",
        "    output_column_name=\"output\",\n",
        "    conversation_extension=3,  # Select more to handle longer conversations\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Kh90vpD1jYJ"
      },
      "source": [
        "Finally use `standardize_sharegpt` to fix up the dataset!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "380fa4b4dd704501a9a9ccee27665264",
            "74db0395e57a4ab5b174996cedec8f10",
            "56395422789d4b60833457ebe04e8478",
            "e75fa6966dff485c8f32fe9f87845e0f",
            "ce133f5daa0b4f44aa64f17339ac59f4",
            "07bee94acc934e818b3820b7cc70665f",
            "a3409eb0f9ea4859b3f26474d5993a49",
            "4bd0cc936da741a6985adbac6c96ffe7",
            "8308a4c3ff3142098c32e989ea1c450e",
            "0b0488359d994f0a919368035bd814c9",
            "01fcf5ebde8048478df5c22f3d2f6193"
          ]
        },
        "id": "ZPwDXBvP1g8S",
        "outputId": "a710fccd-7032-4031-8062-30fc8dfb71f7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Standardizing formats (num_proc=2):   0%|          | 0/7921 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "380fa4b4dd704501a9a9ccee27665264"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from unsloth import standardize_sharegpt\n",
        "\n",
        "dataset = standardize_sharegpt(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmcrTb2_NxAb",
        "outputId": "ff1c9093-e1f1-4f37-b0fc-8ebd8ca55f59"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GThrcKACxTe2"
      },
      "source": [
        "### Customizable Chat Templates\n",
        "\n",
        "You also need to specify a chat template. Previously, you could use the Alpaca format as shown below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MVBanRIJRAcQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2591f800-3076-4cbb-cd6d-b0e4c024fbe2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-bkwq7jrr/unsloth_b8e77e7676084f72b775a07a4d525ee8\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-bkwq7jrr/unsloth_b8e77e7676084f72b775a07a4d525ee8\n",
            "  Resolved https://github.com/unslothai/unsloth.git to commit d4a311d8e71692961e5da1d26d98197fde94f41a\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: unsloth_zoo>=2025.11.5 in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.11.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (25.0)\n",
            "Requirement already satisfied: tyro in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.9.35)\n",
            "Requirement already satisfied: transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.2,>=4.51.3 in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.57.1)\n",
            "Requirement already satisfied: datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1 in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.3.0)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.9.5)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.45.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.0.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.29.5)\n",
            "Requirement already satisfied: huggingface_hub>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.36.0)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.9)\n",
            "Requirement already satisfied: bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5 in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.48.2)\n",
            "Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.20.0)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (22.0.0)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.32.4)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.28.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.2.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.2,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.2,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.2,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.7.0)\n",
            "Requirement already satisfied: torchao>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.11.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.14.1)\n",
            "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.11.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.5.0)\n",
            "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.11.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.11.0)\n",
            "Requirement already satisfied: trl!=0.19.0,<=0.24.0,>=0.18.2 in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.11.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.24.0)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.11.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.18.0)\n",
            "Requirement already satisfied: cut_cross_entropy in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.11.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (25.1.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.11.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.3.0)\n",
            "Requirement already satisfied: msgspec in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.11.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.20.0)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.17.0)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (13.9.4)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.8.0)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.4.4)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.13.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.5.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.19.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.11.1.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.22.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.3)\n",
            "Collecting xformers<0.0.27\n",
            "  Using cached xformers-0.0.26.post1.tar.gz (4.1 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting trl<0.9.0\n",
            "  Using cached trl-0.8.6-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.18.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.48.2)\n",
            "Using cached trl-0.8.6-py3-none-any.whl (245 kB)\n",
            "Building wheels for collected packages: xformers\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m√ó\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m‚îÇ\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for xformers (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for xformers\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for xformers\n",
            "Failed to build xformers\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (xformers)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# COMPLETE WORKING TRAINING SCRIPT FOR YOUR DATASET\n",
        "# ============================================================================\n",
        "\n",
        "# 1. Install Unsloth\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps \"xformers<0.0.27\" \"trl<0.9.0\" peft accelerate bitsandbytes\n",
        "\n",
        "# 2. Import libraries\n",
        "import torch\n",
        "from trl import SFTTrainer\n",
        "from datasets import load_dataset\n",
        "from transformers import TrainingArguments\n",
        "from unsloth.chat_templates import get_chat_template\n",
        "from unsloth import FastLanguageModel, is_bfloat16_supported"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Load model\n",
        "print(\"üì• Loading model...\")\n",
        "max_seq_length = 2048\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=\"unsloth/llama-3-8b-bnb-4bit\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    load_in_4bit=True,\n",
        "    dtype=None,\n",
        ")\n",
        "print(\"‚úÖ Model loaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYwV0tjbNjE3",
        "outputId": "73df06ca-7ce6-4570-f153-8da3bf095579"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Loading model...\n",
            "==((====))==  Unsloth 2025.11.4: Fast Llama patching. Transformers: 4.57.1.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.9.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.5.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = None. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "‚úÖ Model loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Apply QLoRA adapters\n",
        "print(\"‚öôÔ∏è Applying QLoRA...\")\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r=16,\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                    \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0,\n",
        "    bias=\"none\",\n",
        "    use_gradient_checkpointing=\"unsloth\",\n",
        "    random_state=3407,\n",
        ")\n",
        "print(\"‚úÖ QLoRA applied\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2tq8dfGNq2v",
        "outputId": "dbab3714-33b0-4555-db11-7c304e47c52d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚öôÔ∏è Applying QLoRA...\n",
            "‚úÖ QLoRA applied\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Load your dataset (ROBUST METHOD)\n",
        "print(\"üìä Loading dataset...\")\n",
        "import json\n",
        "from datasets import Dataset\n",
        "\n",
        "try:\n",
        "    # Load JSON manually first to avoid pyarrow schema inference errors\n",
        "    with open('/content/comprehensive_requirement_dataset_full.json', 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    # Convert to Hugging Face Dataset\n",
        "    dataset = Dataset.from_list(data)\n",
        "\n",
        "    print(f\"‚úÖ Loaded {len(dataset)} examples\")\n",
        "    print(f\"üìã Columns: {dataset.column_names}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading dataset: {e}\")\n",
        "    # Fallback: Try pandas\n",
        "    import pandas as pd\n",
        "    df = pd.read_json('/content/comprehensive_requirement_dataset_full.json')\n",
        "    dataset = Dataset.from_pandas(df)\n",
        "    print(\"‚úÖ Loaded using Pandas fallback\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uwh4yX_cNWvx",
        "outputId": "1e89195f-eeba-44be-9768-d9b91b790b99"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Loading dataset...\n",
            "‚úÖ Loaded 7921 examples\n",
            "üìã Columns: ['conversations', 'instruction', 'input', 'output']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Apply Llama-3 chat template (FIXED VERSION)\n",
        "print(\"üîß Applying Llama-3 chat template...\")\n",
        "\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    chat_template=\"llama-3\",\n",
        ")\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    \"\"\"Format using the conversations column (ShareGPT format to Llama-3)\"\"\"\n",
        "    convos = examples[\"conversations\"]\n",
        "    texts = []\n",
        "\n",
        "    for convo in convos:\n",
        "        # Convert 'from/value' (ShareGPT) to 'role/content' (Standard)\n",
        "        standard_convo = []\n",
        "        for msg in convo:\n",
        "            role_map = {\n",
        "                \"system\": \"system\",\n",
        "                \"human\": \"user\",\n",
        "                \"gpt\": \"assistant\"\n",
        "            }\n",
        "            standard_convo.append({\n",
        "                \"role\": role_map.get(msg[\"from\"], \"user\"),\n",
        "                \"content\": msg[\"value\"]\n",
        "            })\n",
        "\n",
        "        # Apply template to the converted conversation\n",
        "        text = tokenizer.apply_chat_template(\n",
        "            standard_convo,\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=False\n",
        "        )\n",
        "        texts.append(text)\n",
        "\n",
        "    return {\"text\": texts}\n",
        "\n",
        "# Apply the formatting\n",
        "dataset = dataset.map(formatting_prompts_func, batched=True)\n",
        "print(\"‚úÖ Chat template applied successfully\")"
      ],
      "metadata": {
        "id": "M8QyUrnoTiRm",
        "outputId": "f1a9dfee-dde3-4872-d124-43763605aa51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "9644fafe8d5a4c3cafdfed531342446c",
            "fb1eb289f8df4ddeaf1f3be63ad269a0",
            "790d391e7b124d2ab9a2351f8112f1ed",
            "eaa6131e2eda41958d46e1a1d179c13d",
            "75345f0b396347e680b828c9c12bbdf7",
            "ad9afe9bcddc412286f72408819be170",
            "dc7cb15cef5949b881a157df26e043b3",
            "3cc7a84ba4e04542bf8b47a72ad4ba72",
            "b15fe2c101004aa3b25500c227d0f000",
            "23be1252a7ca4831ab5c65fcdc7ad9a7",
            "331d163fa49b4d87b843419d27c02d85"
          ]
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîß Applying Llama-3 chat template...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/7921 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9644fafe8d5a4c3cafdfed531342446c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Chat template applied successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Setup trainer (OPTIMIZED FOR COLAB T4)\n",
        "print(\"üéì Setting up trainer...\")\n",
        "\n",
        "# Calculate steps for stats display\n",
        "total_steps = (len(dataset) // (2 * 4))  # approx steps\n",
        "logging_steps = max(1, total_steps // 20) # log 20 times per epoch\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=dataset,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=2048,      # Keep context length\n",
        "    dataset_num_proc=2,\n",
        "    packing=False,            # ‚ö†Ô∏è CHANGED: False saves significant memory\n",
        "    args=TrainingArguments(\n",
        "        learning_rate=3e-4,\n",
        "        lr_scheduler_type=\"linear\",\n",
        "        per_device_train_batch_size=2,  # ‚ö†Ô∏è REDUCED: 4 -> 2\n",
        "        gradient_accumulation_steps=8,  # ‚ö†Ô∏è INCREASED: 4 -> 8 (maintains effective batch size 16)\n",
        "        num_train_epochs=1,\n",
        "        fp16=not is_bfloat16_supported(),\n",
        "        bf16=is_bfloat16_supported(),\n",
        "        logging_steps=10,      # Show stats every 10 steps\n",
        "        optim=\"adamw_8bit\",\n",
        "        weight_decay=0.01,\n",
        "        warmup_steps=50,\n",
        "        output_dir=\"output\",\n",
        "        seed=0,\n",
        "        report_to=\"none\",\n",
        "\n",
        "        # Memory optimizations\n",
        "        gradient_checkpointing=True,    # ‚ö†Ô∏è CRITICAL for memory\n",
        "        max_grad_norm=1.0,              # Stabilizes training\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Add callback for better stats (Optional but helpful)\n",
        "from transformers import TrainerCallback\n",
        "class PrinterCallback(TrainerCallback):\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        _ = logs.pop(\"total_flos\", None)\n",
        "        if state.is_local_process_zero:\n",
        "            print(f\"Step {state.global_step}: Loss {logs.get('loss', 'N/A'):.4f}\")\n",
        "\n",
        "trainer.add_callback(PrinterCallback)\n",
        "\n",
        "print(\"‚úÖ Trainer ready with memory optimizations\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "1b58a2542ca740bb9de91737e72bac3d",
            "0d30ba03bb4c4b3bb1e1b972b017c353",
            "574c5b3155034fcf90cb798f96ab3a7f",
            "319e1444938247239486ac86f2b454fb",
            "8762f1b75f02443db75f29c06ed08b80",
            "7f79e27de9034321a29706c0915c6ef2",
            "7db6014c1ce847808dbffd34a86144c7",
            "eccb322f704844df85026fdba73e9d30",
            "1cc5c69f172149d1a1e16eee024b8d72",
            "709c8c84bb894d9881319f7c479ff735",
            "f2d51fd8d989464aa30fe9f66947034b"
          ]
        },
        "id": "UwZAdWv9O2uw",
        "outputId": "c617372c-0e5f-40dc-f117-f9a76c149146"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéì Setting up trainer...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"] (num_proc=6):   0%|          | 0/7921 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b58a2542ca740bb9de91737e72bac3d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Trainer ready with memory optimizations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "TfMSHvXbWdwm"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 8. Start training\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üöÄ STARTING TRAINING...\")\n",
        "print(\"=\"*60)\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DhgoemNgO6zI",
        "outputId": "bfcd42d3-bfb5-40c3-d103-d178c94ad8dc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "üöÄ STARTING TRAINING...\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 7,921 | Num Epochs = 1 | Total steps = 496\n",
            "O^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 4 x 1) = 16\n",
            " \"-____-\"     Trainable parameters = 41,943,040 of 8,072,204,288 (0.52% trained)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 142.12 MiB is free. Process 3672 has 14.60 GiB memory in use. Of the allocated memory 13.10 GiB is allocated by PyTorch, and 1.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3027141179.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"üöÄ STARTING TRAINING...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/unsloth_compiled_cache/UnslothSFTTrainer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"for_training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;31m# Return inference mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"for_inference\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2324\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2325\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2326\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2327\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36m_fast_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n",
            "\u001b[0;32m/content/unsloth_compiled_cache/UnslothSFTTrainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_activation_offload_context\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/unsloth/models/_utils.py\u001b[0m in \u001b[0;36m_unsloth_training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2734\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2735\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2737\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_lomo_optimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2738\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlomo_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             )\n\u001b[0;32m--> 625\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    313\u001b[0m             )\n\u001b[1;32m    314\u001b[0m         \u001b[0muser_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvjp_fn\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvjp_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvjp\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mbackward_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0muser_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_jvp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/unsloth_zoo/gradient_checkpointing.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(ctx, *args)\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;31m# )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs_with_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_with_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 142.12 MiB is free. Process 3672 has 14.60 GiB memory in use. Of the allocated memory 13.10 GiB is allocated by PyTorch, and 1.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTzZ5oZrxkFz"
      },
      "source": [
        "Now, you have to use `{INPUT}` for the instruction and `{OUTPUT}` for the response.\n",
        "\n",
        "We also allow you to use an optional `{SYSTEM}` field. This is useful for Ollama when you want to use a custom system prompt (also like in ChatGPT).\n",
        "\n",
        "You can also not put a `{SYSTEM}` field, and just put plain text.\n",
        "\n",
        "```python\n",
        "chat_template = \"\"\"{SYSTEM}\n",
        "USER: {INPUT}\n",
        "ASSISTANT: {OUTPUT}\"\"\"\n",
        "```\n",
        "\n",
        "Use below if you want to use the Llama-3 prompt format. You must use the `instruct` and not the `base` model if you use this!\n",
        "```python\n",
        "chat_template = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
        "\n",
        "{SYSTEM}<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "{INPUT}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "\n",
        "{OUTPUT}<|eot_id|>\"\"\"\n",
        "```\n",
        "\n",
        "For the ChatML format:\n",
        "```python\n",
        "chat_template = \"\"\"<|im_start|>system\n",
        "{SYSTEM}<|im_end|>\n",
        "<|im_start|>user\n",
        "{INPUT}<|im_end|>\n",
        "<|im_start|>assistant\n",
        "{OUTPUT}<|im_end|>\"\"\"\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EK-_ncj-RCNy"
      },
      "source": [
        "The issue is the Alpaca format has 3 fields, whilst OpenAI style chatbots must only use 2 fields (instruction and response). That's why we used the `to_sharegpt` function to merge these columns into 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458,
          "referenced_widgets": [
            "4da576b5c78d4098ab1ee9779394d856",
            "bf390d8bf4df447787c94e74ee0db8fb",
            "355d5195566d4b61b4156de40149633d",
            "f4dcd0789eae4fe182d5a2dd7557b029",
            "e55f71f67f564bf795db57edbbb81632",
            "dc924ef5b998460b83c80e291b5abf17",
            "1005790d601346ea964e002e36d8d5a2",
            "10c7b90b26b94c8ea545031259653f8c",
            "5381ef010c1040ebb0d633903af0ccc9",
            "fe53dc5367f94c1db0ba92cafa7d78a1",
            "3533c249ab484b5b939f017e32fc8069"
          ]
        },
        "id": "JOGaZf1sdLlr",
        "outputId": "2b4e7529-0e2d-4fb6-ec50-f7e1838bc15a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: We automatically added an EOS token to stop endless generations.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/7921 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4da576b5c78d4098ab1ee9779394d856"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "TemplateError",
          "evalue": "Only user and assistant roles are supported!",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTemplateError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-712726702.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0munsloth\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapply_chat_template\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m dataset = apply_chat_template(\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/unsloth/chat_templates.py\u001b[0m in \u001b[0;36mapply_chat_template\u001b[0;34m(dataset, tokenizer, chat_template, default_system_message, extra_eos_tokens)\u001b[0m\n\u001b[1;32m   2958\u001b[0m         \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unsloth_output_part\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2960\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformatting_prompts_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    555\u001b[0m         }\n\u001b[1;32m    556\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0;31m# re-apply format to the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc, try_original_type)\u001b[0m\n\u001b[1;32m   3077\u001b[0m                     \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"Map\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m                 ) as pbar:\n\u001b[0;32m-> 3079\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdataset_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3080\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m                             \u001b[0mshards_done\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, try_original_type)\u001b[0m\n\u001b[1;32m   3523\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3524\u001b[0m                     \u001b[0m_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3525\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshard_iterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3526\u001b[0m                         \u001b[0mnum_examples_in_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3527\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mupdate_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36miter_outputs\u001b[0;34m(shard_iterable)\u001b[0m\n\u001b[1;32m   3473\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3474\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshard_iterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3475\u001b[0;31m                     \u001b[0;32myield\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3477\u001b[0m         \u001b[0mnum_examples_progress_update\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mapply_function\u001b[0;34m(pa_inputs, indices, offset)\u001b[0m\n\u001b[1;32m   3396\u001b[0m             \u001b[0;34m\"\"\"Utility to apply the function on a selection of columns.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3397\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditional_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3398\u001b[0;31m             \u001b[0mprocessed_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0madditional_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3399\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mprepare_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessed_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/unsloth/chat_templates.py\u001b[0m in \u001b[0;36mformatting_prompts_func\u001b[0;34m(examples)\u001b[0m\n\u001b[1;32m   2945\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mformatting_prompts_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2946\u001b[0m         \u001b[0mconvos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"conversations\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2947\u001b[0;31m         \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_chat_template\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_generation_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mconvo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconvos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2948\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m \u001b[0;34m\"text\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mapply_chat_template\u001b[0;34m(self, conversation, tools, documents, chat_template, add_generation_prompt, continue_final_message, tokenize, padding, truncation, max_length, return_tensors, return_dict, return_assistant_tokens_mask, tokenizer_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m   1638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1639\u001b[0m         \u001b[0mtemplate_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial_tokens_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m}\u001b[0m  \u001b[0;31m# kwargs overwrite special tokens if both are present\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1640\u001b[0;31m         rendered_chat, generation_indices = render_jinja_template(\n\u001b[0m\u001b[1;32m   1641\u001b[0m             \u001b[0mconversations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconversations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1642\u001b[0m             \u001b[0mtools\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/chat_template_utils.py\u001b[0m in \u001b[0;36mrender_jinja_template\u001b[0;34m(conversations, tools, documents, chat_template, return_assistant_tokens_mask, continue_final_message, add_generation_prompt, **kwargs)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0mall_generation_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneration_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             rendered_chat = compiled_template.render(\n\u001b[0m\u001b[1;32m    522\u001b[0m                 \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0mtools\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtool_schemas\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/jinja2/environment.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1293\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_render_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrender_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/jinja2/environment.py\u001b[0m in \u001b[0;36mhandle_exception\u001b[0;34m(self, source)\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrewrite_traceback_stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mrewrite_traceback_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mjoin_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<template>\u001b[0m in \u001b[0;36mtop-level template code\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/jinja2/sandbox.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(_SandboxedEnvironment__self, _SandboxedEnvironment__context, _SandboxedEnvironment__obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m__self\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_safe_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mSecurityError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{__obj!r} is not safely callable\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m__context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/chat_template_utils.py\u001b[0m in \u001b[0;36mraise_exception\u001b[0;34m(message)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mraise_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mjinja2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTemplateError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtojson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ascii\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseparators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTemplateError\u001b[0m: Only user and assistant roles are supported!"
          ]
        }
      ],
      "source": [
        "chat_template = \"\"\"Below are some instructions that describe some tasks. Write responses that appropriately complete each request.\n",
        "\n",
        "### Instruction:\n",
        "{INPUT}\n",
        "\n",
        "### Response:\n",
        "{OUTPUT}\"\"\"\n",
        "\n",
        "from unsloth import apply_chat_template\n",
        "\n",
        "dataset = apply_chat_template(\n",
        "    dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    chat_template=chat_template,\n",
        "    # default_system_message = \"You are a helpful assistant\", << [OPTIONAL]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idAEIeSQ3xdS"
      },
      "source": [
        "<a name=\"Train\"></a>\n",
        "### Train the model\n",
        "Now let's train our model. We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`. We also support TRL's `DPOTrainer`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "dee51ee264e24b809be18f6d286ae874",
            "a9a39684291d4eb1b7312640feae1462",
            "d7435502d95f4355b37d2f3332b057f1",
            "2d15261428824594908bd697644d61ed",
            "b3a8a71922f341758e1adf0f951208bb",
            "7f107e2a1d274a2f9bec4acce979d2da",
            "0d5da7e017424aa0b7ff0d40abad1ecc",
            "4c4bc99385eb49dd95ad4b740b949e55",
            "f62d1a6521574459ae6fb1ebd71ad631",
            "62191c10c14c4728bf85a293d29d37ce",
            "ec56936c53984c85ade94df6ce443ad5"
          ]
        },
        "id": "95_Nn-89DhsL",
        "outputId": "27f7cc9d-8fd9-4111-ee2d-a5a434b30282"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dee51ee264e24b809be18f6d286ae874",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/52002 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        }
      ],
      "source": [
        "from trl import SFTConfig, SFTTrainer\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    packing = False, # Can make training 5x faster for short sequences.\n",
        "    args = SFTConfig(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        max_steps = 60,\n",
        "        # num_train_epochs = 1, # For longer training runs!\n",
        "        learning_rate = 2e-4,\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.001,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "        report_to = \"none\", # Use TrackIO/WandB etc\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ejIt2xSNKKp",
        "outputId": "623e558b-a1c9-425b-feff-4dcdbc381d0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU = Tesla T4. Max memory = 14.748 GB.\n",
            "5.613 GB of memory reserved.\n"
          ]
        }
      ],
      "source": [
        "# @title Show current memory stats\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yqxqAZ7KJ4oL",
        "outputId": "fd7d79c2-68a7-4e3a-e567-adecc3b1be87"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
            "   \\\\   /|    Num examples = 52,002 | Num Epochs = 1\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
            "\\        /    Total batch size = 8 | Total steps = 60\n",
            " \"-____-\"     Number of trainable parameters = 41,943,040\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 14:46, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.530300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.521200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.419800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.496600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.618100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.255100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.290100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.277400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.323600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.166000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.204200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.189000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.049100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.115200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.150700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.051400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.051000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.173100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.129600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.104200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>1.033500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>1.111600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.966300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.042500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.017800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>1.071600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>1.092100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>1.074600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>1.077500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.122200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>1.066400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>1.154400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.980800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>1.074700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>1.155100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>1.142200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>1.047400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>1.024000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.990800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.018900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>1.025600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>1.039400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>1.166000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>1.086500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>1.001300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>1.040000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>1.076200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>1.120800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>1.020300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.238000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>1.094100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>1.112800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>1.098000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.985200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>1.009800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>1.034200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>1.018500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>1.043500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.986100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.032200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCqnaKmlO1U9",
        "outputId": "38fed629-e855-4386-c150-8578e0a73a15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "910.2379 seconds used for training.\n",
            "15.17 minutes used for training.\n",
            "Peak reserved memory = 8.361 GB.\n",
            "Peak reserved memory for training = 2.748 GB.\n",
            "Peak reserved memory % of max memory = 56.692 %.\n",
            "Peak reserved memory for training % of max memory = 18.633 %.\n"
          ]
        }
      ],
      "source": [
        "# @title Show final memory and time stats\n",
        "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
        "used_percentage = round(used_memory / max_memory * 100, 3)\n",
        "lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
        "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "print(\n",
        "    f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\"\n",
        ")\n",
        "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
        "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
        "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekOmTR1hSNcr"
      },
      "source": [
        "<a name=\"Inference\"></a>\n",
        "### Inference\n",
        "Let's run the model! Unsloth makes inference natively 2x faster as well! You should use prompts which are similar to the ones you had finetuned on, otherwise you might get bad results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kR3gIAX-SM2q",
        "outputId": "40b5e499-1ad5-4907-a284-9416a36d010c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The next number in the Fibonacci sequence is 13.<|end_of_text|>\n"
          ]
        }
      ],
      "source": [
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "messages = [                    # Change below!\n",
        "    {\"role\": \"user\", \"content\": \"Continue the fibonacci sequence! Your input is 1, 1, 2, 3, 5, 8,\"},\n",
        "]\n",
        "input_ids = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    add_generation_prompt = True,\n",
        "    return_tensors = \"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
        "_ = model.generate(input_ids, streamer = text_streamer, max_new_tokens = 128, pad_token_id = tokenizer.eos_token_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrSvZObor0lY"
      },
      "source": [
        "Since we created an actual chatbot, you can also do longer conversations by manually adding alternating conversations between the user and assistant!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcbFUWEyQVaE",
        "outputId": "517ed3fe-009e-4ebf-d233-2883e943de82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "France's tallest tower is called the Eiffel Tower.<|end_of_text|>\n"
          ]
        }
      ],
      "source": [
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "messages = [                         # Change below!\n",
        "    {\"role\": \"user\",      \"content\": \"Continue the fibonacci sequence! Your input is 1, 1, 2, 3, 5, 8\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"The fibonacci sequence continues as 13, 21, 34, 55 and 89.\"},\n",
        "    {\"role\": \"user\",      \"content\": \"What is France's tallest tower called?\"},\n",
        "]\n",
        "input_ids = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    add_generation_prompt = True,\n",
        "    return_tensors = \"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
        "_ = model.generate(input_ids, streamer = text_streamer, max_new_tokens = 128, pad_token_id = tokenizer.eos_token_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMuVrWbjAzhc"
      },
      "source": [
        "<a name=\"Save\"></a>\n",
        "### Saving, loading finetuned models\n",
        "To save the final model as LoRA adapters, either use Huggingface's `push_to_hub` for an online save or `save_pretrained` for a local save.\n",
        "\n",
        "**[NOTE]** This ONLY saves the LoRA adapters, and not the full model. To save to 16bit or GGUF, scroll down!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upcOlWe7A1vc",
        "outputId": "587e0389-0044-47a2-f691-581d262ea95c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('lora_model/tokenizer_config.json',\n",
              " 'lora_model/special_tokens_map.json',\n",
              " 'lora_model/tokenizer.json')"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.save_pretrained(\"lora_model\")  # Local saving\n",
        "tokenizer.save_pretrained(\"lora_model\")\n",
        "# model.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving\n",
        "# tokenizer.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEEcJ4qfC7Lp"
      },
      "source": [
        "Now if you want to load the LoRA adapters we just saved for inference, set `False` to `True`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKX_XKs_BNZR",
        "outputId": "98ec2273-2e01-4062-c576-1ffb7b3afdb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sequence 1, 1, 2, 3, 5, 8 is a special sequence known as the Fibonacci sequence. The Fibonacci sequence is a series of numbers where each number is the sum of the two previous numbers, starting with 0 and 1. In this case, the sequence is 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, and so on. The Fibonacci sequence has many interesting properties and is widely studied in mathematics and computer science.<|end_of_text|>\n"
          ]
        }
      ],
      "source": [
        "if False:\n",
        "    from unsloth import FastLanguageModel\n",
        "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name = \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "        max_seq_length = max_seq_length,\n",
        "        dtype = dtype,\n",
        "        load_in_4bit = load_in_4bit,\n",
        "    )\n",
        "    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "messages = [                    # Change below!\n",
        "    {\"role\": \"user\", \"content\": \"Describe anything special about a sequence. Your input is 1, 1, 2, 3, 5, 8,\"},\n",
        "]\n",
        "input_ids = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    add_generation_prompt = True,\n",
        "    return_tensors = \"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
        "_ = model.generate(input_ids, streamer = text_streamer, max_new_tokens = 128, pad_token_id = tokenizer.eos_token_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQMjaNrjsU5_"
      },
      "source": [
        "You can also use Hugging Face's `AutoModelForPeftCausalLM`. Only use this if you do not have `unsloth` installed. It can be hopelessly slow, since `4bit` model downloading is not supported, and Unsloth's **inference is 2x faster**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFfaXG0WsQuE"
      },
      "outputs": [],
      "source": [
        "if False:\n",
        "    # I highly do NOT suggest - use Unsloth if possible\n",
        "    from peft import AutoPeftModelForCausalLM\n",
        "    from transformers import AutoTokenizer\n",
        "    model = AutoPeftModelForCausalLM.from_pretrained(\n",
        "        \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "        load_in_4bit = load_in_4bit,\n",
        "    )\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"lora_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOFzC441vCtq"
      },
      "source": [
        "<a name=\"Ollama\"></a>\n",
        "### Ollama Support\n",
        "\n",
        "[Unsloth](https://github.com/unslothai/unsloth) now allows you to automatically finetune and create a [Modelfile](https://github.com/ollama/ollama/blob/main/docs/modelfile.md), and export to [Ollama](https://ollama.com/)! This makes finetuning much easier and provides a seamless workflow from `Unsloth` to `Ollama`!\n",
        "\n",
        "Let's first install `Ollama`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUxcyP_UfeLl",
        "outputId": "69972ce0-9caf-41fd-b19a-fa058521990b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> Installing ollama to /usr/local\n",
            ">>> Downloading Linux amd64 bundle\n",
            "############################################################################################# 100.0%\n",
            ">>> Creating ollama user...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "WARNING: Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n"
          ]
        }
      ],
      "source": [
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCv4vXHd61i7"
      },
      "source": [
        "Next, we shall save the model to GGUF / llama.cpp\n",
        "\n",
        "We clone `llama.cpp` and we default save it to `q8_0`. We allow all methods like `q4_k_m`. Use `save_pretrained_gguf` for local saving and `push_to_hub_gguf` for uploading to HF.\n",
        "\n",
        "Some supported quant methods (full list on our [Wiki page](https://github.com/unslothai/unsloth/wiki#gguf-quantization-options)):\n",
        "* `q8_0` - Fast conversion. High resource use, but generally acceptable.\n",
        "* `q4_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q4_K.\n",
        "* `q5_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q5_K.\n",
        "\n",
        "We also support saving to multiple GGUF options in a list fashion! This can speed things up by 10 minutes or more if you want multiple export formats!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqfebeAdT073",
        "outputId": "9d2292eb-1e31-4c88-9b44-5371e4104abf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth: ##### The current model auto adds a BOS token.\n",
            "Unsloth: ##### Your chat template has a BOS token. We shall remove it temporarily.\n",
            "Unsloth: You have 1 CPUs. Using `safe_serialization` is 10x slower.\n",
            "We shall switch to Pytorch saving, which will take 3 minutes and not 30 minutes.\n",
            "To force `safe_serialization`, set it to `None` instead.\n",
            "Unsloth: Kaggle/Colab has limited disk space. We need to delete the downloaded\n",
            "model which will save 4-16GB of disk space, allowing you to save on Kaggle/Colab.\n",
            "Unsloth: Will remove a cached repo with size 5.7G\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
            "Unsloth: Will use up to 5.49 out of 12.67 RAM for saving.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 15/32 [00:01<00:01,  9.79it/s]We will save to Disk and not RAM now.\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [01:41<00:00,  3.18s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: Saving tokenizer... Done.\n",
            "Unsloth: Saving model... This might take 5 minutes for Llama-7b...\n",
            "Unsloth: Saving model/pytorch_model-00001-of-00004.bin...\n",
            "Unsloth: Saving model/pytorch_model-00002-of-00004.bin...\n",
            "Unsloth: Saving model/pytorch_model-00003-of-00004.bin...\n",
            "Unsloth: Saving model/pytorch_model-00004-of-00004.bin...\n",
            "Done.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth: Converting llama model. Can use fast conversion = False.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n",
            "   \\\\   /|    [0] Installing llama.cpp will take 3 minutes.\n",
            "O^O/ \\_/ \\    [1] Converting HF to GGUF 16bits will take 3 minutes.\n",
            "\\        /    [2] Converting GGUF 16bits to ['q8_0'] will take 10 minutes each.\n",
            " \"-____-\"     In total, you will have to wait at least 16 minutes.\n",
            "\n",
            "Unsloth: [0] Installing llama.cpp. This will take 3 minutes...\n",
            "Unsloth: [1] Converting model at model into q8_0 GGUF format.\n",
            "The output location will be ./model/unsloth.Q8_0.gguf\n",
            "This will take 3 minutes...\n",
            "INFO:hf-to-gguf:Loading model: model\n",
            "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
            "INFO:hf-to-gguf:Exporting model...\n",
            "INFO:hf-to-gguf:gguf: loading model weight map from 'pytorch_model.bin.index.json'\n",
            "INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00001-of-00004.bin'\n",
            "INFO:hf-to-gguf:token_embd.weight,           torch.float16 --> Q8_0, shape = {4096, 128256}\n",
            "INFO:hf-to-gguf:blk.0.attn_q.weight,         torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.0.attn_k.weight,         torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.0.attn_v.weight,         torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.0.attn_output.weight,    torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.0.ffn_gate.weight,       torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.0.ffn_up.weight,         torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.0.ffn_down.weight,       torch.float16 --> Q8_0, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.0.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.0.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.1.attn_q.weight,         torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.1.attn_k.weight,         torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.1.attn_v.weight,         torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.1.attn_output.weight,    torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.1.ffn_gate.weight,       torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.1.ffn_up.weight,         torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.1.ffn_down.weight,       torch.float16 --> Q8_0, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.1.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.1.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.2.attn_q.weight,         torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.2.attn_k.weight,         torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.2.attn_v.weight,         torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.2.attn_output.weight,    torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.2.ffn_gate.weight,       torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.2.ffn_up.weight,         torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.2.ffn_down.weight,       torch.float16 --> Q8_0, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.2.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.2.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.3.attn_q.weight,         torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.3.attn_k.weight,         torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.3.attn_v.weight,         torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.3.attn_output.weight,    torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.3.ffn_gate.weight,       torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.3.ffn_up.weight,         torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.3.ffn_down.weight,       torch.float16 --> Q8_0, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.3.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.3.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.4.attn_q.weight,         torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.4.attn_k.weight,         torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.4.attn_v.weight,         torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.4.attn_output.weight,    torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.4.ffn_gate.weight,       torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.4.ffn_up.weight,         torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.4.ffn_down.weight,       torch.float16 --> Q8_0, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.4.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.4.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.5.attn_q.weight,         torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.5.attn_k.weight,         torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.5.attn_v.weight,         torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.5.attn_output.weight,    torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.5.ffn_gate.weight,       torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.5.ffn_up.weight,         torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.5.ffn_down.weight,       torch.float16 --> Q8_0, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.5.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.5.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.6.attn_q.weight,         torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.6.attn_k.weight,         torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.6.attn_v.weight,         torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.6.attn_output.weight,    torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.6.ffn_gate.weight,       torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.6.ffn_up.weight,         torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.6.ffn_down.weight,       torch.float16 --> Q8_0, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.6.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.6.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.7.attn_q.weight,         torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.7.attn_k.weight,         torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.7.attn_v.weight,         torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.7.attn_output.weight,    torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.7.ffn_gate.weight,       torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.7.ffn_up.weight,         torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.7.ffn_down.weight,       torch.float16 --> Q8_0, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.7.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.7.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.8.attn_q.weight,         torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.8.attn_k.weight,         torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.8.attn_v.weight,         torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.8.attn_output.weight,    torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.8.ffn_gate.weight,       torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.8.ffn_up.weight,         torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.8.ffn_down.weight,       torch.float16 --> Q8_0, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.8.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.8.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00002-of-00004.bin'\n",
            "INFO:hf-to-gguf:blk.9.attn_q.weight,         torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.9.attn_k.weight,         torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.9.attn_v.weight,         torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.9.attn_output.weight,    torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.9.ffn_gate.weight,       torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.9.ffn_up.weight,         torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.9.ffn_down.weight,       torch.float16 --> Q8_0, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.9.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.9.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.10.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.10.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.10.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.10.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.10.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.10.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.10.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.10.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.10.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.11.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.11.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.11.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.11.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.11.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.11.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.11.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.11.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.11.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.12.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.12.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.12.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.12.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.12.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.12.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.12.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.12.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.12.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.13.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.13.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.13.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.13.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.13.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.13.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.13.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.13.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.13.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.14.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.14.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.14.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.14.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.14.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.14.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.14.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.14.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.14.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.15.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.15.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.15.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.15.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.15.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.15.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.15.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.15.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.15.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.16.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.16.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.16.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.16.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.16.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.16.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.16.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.16.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.16.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.17.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.17.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.17.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.17.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.17.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.17.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.17.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.17.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.17.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.18.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.18.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.18.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.18.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.18.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.18.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.18.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.18.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.18.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.19.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.19.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.19.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.19.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.19.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.19.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.19.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.19.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.19.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.20.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.20.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.20.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.20.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.20.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00003-of-00004.bin'\n",
            "INFO:hf-to-gguf:blk.20.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.20.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.20.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.20.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.21.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.21.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.21.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.21.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.21.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.21.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.21.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.21.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.21.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.22.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.22.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.22.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.22.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.22.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.22.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.22.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.22.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.22.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.23.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.23.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.23.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.23.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.23.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.23.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.23.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.23.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.23.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.24.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.24.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.24.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.24.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.24.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.24.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.24.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.24.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.24.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.25.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.25.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.25.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.25.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.25.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.25.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.25.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.25.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.25.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.26.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.26.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.26.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.26.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.26.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.26.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.26.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.26.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.26.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.27.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.27.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.27.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.27.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.27.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.27.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.27.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.27.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.27.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.28.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.28.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.28.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.28.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.28.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.28.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.28.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.28.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.28.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.29.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.29.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.29.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.29.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.29.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.29.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.29.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.29.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.29.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.30.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.30.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.30.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.30.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.30.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.30.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.30.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.30.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.30.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.31.attn_q.weight,        torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.31.attn_k.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.31.attn_v.weight,        torch.float16 --> Q8_0, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.31.attn_output.weight,   torch.float16 --> Q8_0, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.31.ffn_gate.weight,      torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.31.ffn_up.weight,        torch.float16 --> Q8_0, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00004-of-00004.bin'\n",
            "INFO:hf-to-gguf:blk.31.ffn_down.weight,      torch.float16 --> Q8_0, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.31.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.31.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:output_norm.weight,          torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:output.weight,               torch.float16 --> Q8_0, shape = {4096, 128256}\n",
            "INFO:hf-to-gguf:Set meta model\n",
            "INFO:hf-to-gguf:Set model parameters\n",
            "INFO:hf-to-gguf:gguf: context length = 8192\n",
            "INFO:hf-to-gguf:gguf: embedding length = 4096\n",
            "INFO:hf-to-gguf:gguf: feed forward length = 14336\n",
            "INFO:hf-to-gguf:gguf: head count = 32\n",
            "INFO:hf-to-gguf:gguf: key-value head count = 8\n",
            "INFO:hf-to-gguf:gguf: rope theta = 500000.0\n",
            "INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-05\n",
            "INFO:hf-to-gguf:gguf: file type = 7\n",
            "INFO:hf-to-gguf:Set model tokenizer\n",
            "INFO:gguf.vocab:Adding 280147 merge(s).\n",
            "INFO:gguf.vocab:Setting special token type bos to 128000\n",
            "INFO:gguf.vocab:Setting special token type eos to 128001\n",
            "INFO:gguf.vocab:Setting special token type pad to 128255\n",
            "INFO:gguf.vocab:Setting chat_template to {{ 'Below are some instructions that describe some tasks. Write responses that appropriately complete each request.' }}{% for message in messages %}{% if message['role'] == 'user' %}{{ '\n",
            "\n",
            "### Instruction:\n",
            "' + message['content'] }}{% elif message['role'] == 'assistant' %}{{ '\n",
            "\n",
            "### Response:\n",
            "' + message['content'] + '<|end_of_text|>' }}{% else %}{{ raise_exception('Only user and assistant roles are supported!') }}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '\n",
            "\n",
            "### Response:\n",
            "' }}{% endif %}\n",
            "INFO:hf-to-gguf:Set model quantization version\n",
            "INFO:gguf.gguf_writer:Writing the following files:\n",
            "INFO:gguf.gguf_writer:model/unsloth.Q8_0.gguf: n_tensors = 291, total_size = 8.5G\n",
            "Writing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8.53G/8.53G [03:05<00:00, 46.1Mbyte/s]\n",
            "INFO:hf-to-gguf:Model successfully exported to model/unsloth.Q8_0.gguf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth: ##### The current model auto adds a BOS token.\n",
            "Unsloth: ##### We removed it in GGUF's chat template for you.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: Conversion completed! Output location: ./model/unsloth.Q8_0.gguf\n",
            "Unsloth: Saved Ollama Modelfile to model/Modelfile\n"
          ]
        }
      ],
      "source": [
        "# Save to 8bit Q8_0\n",
        "if True: model.save_pretrained_gguf(\"model\", tokenizer,)\n",
        "# Remember to go to https://huggingface.co/settings/tokens for a token!\n",
        "# And change hf to your username!\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, token = \"\")\n",
        "\n",
        "# Save to 16bit GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"f16\", token = \"\")\n",
        "\n",
        "# Save to q4_k_m GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"q4_k_m\", token = \"\")\n",
        "\n",
        "# Save to multiple GGUF options - much faster if you want multiple!\n",
        "if False:\n",
        "    model.push_to_hub_gguf(\n",
        "        \"hf/model\", # Change hf to your username!\n",
        "        tokenizer,\n",
        "        quantization_method = [\"q4_k_m\", \"q8_0\", \"q5_k_m\",],\n",
        "        token = \"\", # Get a token at https://huggingface.co/settings/tokens\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7lk6l0CuPXS"
      },
      "source": [
        "We use `subprocess` to start `Ollama` up in a non blocking fashion! In your own desktop, you can simply open up a new `terminal` and type `ollama serve`, but in Colab, we have to use this hack!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcP9omF_tN7Q"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "subprocess.Popen([\"ollama\", \"serve\"])\n",
        "import time\n",
        "\n",
        "time.sleep(3)  # Wait for a few seconds for Ollama to load!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "md3PExRLRhOc"
      },
      "source": [
        "`Ollama` needs a `Modelfile`, which specifies the model's prompt format. Let's print Unsloth's auto generated one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h82vfNigRhiz",
        "outputId": "bcd91437-d4cf-47de-8905-475e3fc4deec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FROM {__FILE_LOCATION__}\n",
            "\n",
            "TEMPLATE \"\"\"Below are some instructions that describe some tasks. Write responses that appropriately complete each request.{{ if .Prompt }}\n",
            "\n",
            "### Instruction:\n",
            "{{ .Prompt }}{{ end }}\n",
            "\n",
            "### Response:\n",
            "{{ .Response }}<|end_of_text|>\"\"\"\n",
            "\n",
            "PARAMETER stop \"<|eot_id|>\"\n",
            "PARAMETER stop \"<|start_header_id|>\"\n",
            "PARAMETER stop \"<|end_header_id|>\"\n",
            "PARAMETER stop \"<|end_of_text|>\"\n",
            "PARAMETER stop \"<|reserved_special_token_\"\n",
            "PARAMETER temperature 1.5\n",
            "PARAMETER min_p 0.1\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer._ollama_modelfile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6cipBJBudxv"
      },
      "source": [
        "We now will create an `Ollama` model called `unsloth_model` using the `Modelfile` which we auto generated!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDTUJv_QiaVh",
        "outputId": "66fcae42-3792-4b52-eb42-d867d9f83d69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25ltransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¶ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†è \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†º \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†¥ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ß \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†á \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ‚†∏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data \n",
            "creating new layer sha256:94728011329d3d304c40e235f81f1b75580e163036c07d98382dc5548d555a34 \n",
            "creating new layer sha256:95b5361453780fb5797ce5abfe9a330f5d33fdec13d2232ef1443ee0c3a86ecc \n",
            "creating new layer sha256:57675488fe3dd2a75da06ae97984c4ce6f382208e9d989c584b22ee395bab0d8 \n",
            "creating new layer sha256:e706dd26476841ded603017f70f5b99b5be356caa859878787bfc3898d547f08 \n",
            "writing manifest \n",
            "success \u001b[?25h\n"
          ]
        }
      ],
      "source": [
        "!ollama create unsloth_model -f ./model/Modelfile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KSoKTKQukba"
      },
      "source": [
        "And now we can do inference on it via `Ollama`!\n",
        "\n",
        "You can also upload to `Ollama` and try the `Ollama` Desktop app by heading to https://www.ollama.com/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkp0uMrNpYaW",
        "outputId": "38bb3bd7-4a29-4c81-e319-388dcd96a449"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:04.241326628Z\",\"message\":{\"role\":\"assistant\",\"content\":\"The\"},\"done\":false}\n",
            "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:04.465575479Z\",\"message\":{\"role\":\"assistant\",\"content\":\" next\"},\"done\":false}\n",
            "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:04.760101468Z\",\"message\":{\"role\":\"assistant\",\"content\":\" number\"},\"done\":false}\n",
            "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:05.051240606Z\",\"message\":{\"role\":\"assistant\",\"content\":\" in\"},\"done\":false}\n",
            "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:05.376545126Z\",\"message\":{\"role\":\"assistant\",\"content\":\" the\"},\"done\":false}\n",
            "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:05.515751946Z\",\"message\":{\"role\":\"assistant\",\"content\":\" Fibonacci\"},\"done\":false}\n",
            "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:05.658721744Z\",\"message\":{\"role\":\"assistant\",\"content\":\" sequence\"},\"done\":false}\n",
            "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:05.795226527Z\",\"message\":{\"role\":\"assistant\",\"content\":\" after\"},\"done\":false}\n",
            "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:05.923676364Z\",\"message\":{\"role\":\"assistant\",\"content\":\" \"},\"done\":false}\n",
            "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:06.053599585Z\",\"message\":{\"role\":\"assistant\",\"content\":\"8\"},\"done\":false}\n",
            "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:06.187220374Z\",\"message\":{\"role\":\"assistant\",\"content\":\" is\"},\"done\":false}\n",
            "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:06.316237671Z\",\"message\":{\"role\":\"assistant\",\"content\":\" \"},\"done\":false}\n",
            "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:06.448901764Z\",\"message\":{\"role\":\"assistant\",\"content\":\"13\"},\"done\":false}\n",
            "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:06.585864644Z\",\"message\":{\"role\":\"assistant\",\"content\":\" (\"},\"done\":false}\n",
            "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:06.712030586Z\",\"message\":{\"role\":\"assistant\",\"content\":\"the\"},\"done\":false}\n",
            "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:06.835728964Z\",\"message\":{\"role\":\"assistant\",\"content\":\" sum\"},\"done\":false}\n",
            "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:06.962898827Z\",\"message\":{\"role\":\"assistant\",\"content\":\" of\"},\"done\":false}\n",
            "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:07.088064406Z\",\"message\":{\"role\":\"assistant\",\"content\":\" the\"},\"done\":false}\n",
            "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:07.212942126Z\",\"message\":{\"role\":\"assistant\",\"content\":\" previous\"},\"done\":false}\n",
            "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:07.336569966Z\",\"message\":{\"role\":\"assistant\",\"content\":\" two\"},\"done\":false}\n",
            "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:07.46094096Z\",\"message\":{\"role\":\"assistant\",\"content\":\" numbers\"},\"done\":false}\n",
            "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:07.593857726Z\",\"message\":{\"role\":\"assistant\",\"content\":\").\"},\"done\":false}\n",
            "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:07.741203726Z\",\"message\":{\"role\":\"assistant\",\"content\":\"\"},\"done_reason\":\"stop\",\"done\":true,\"total_duration\":3741960321,\"load_duration\":48967410,\"prompt_eval_count\":47,\"prompt_eval_duration\":150430000,\"eval_count\":23,\"eval_duration\":3499634000}\n"
          ]
        }
      ],
      "source": [
        "!curl http://localhost:11434/api/chat -d '{ \\\n",
        "    \"model\": \"unsloth_model\", \\\n",
        "    \"messages\": [ \\\n",
        "        { \"role\": \"user\", \"content\": \"Continue the Fibonacci sequence: 1, 1, 2, 3, 5, 8,\" } \\\n",
        "    ] \\\n",
        "    }'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnMbhp7KsKhr"
      },
      "source": [
        "# ChatGPT interactive mode\n",
        "\n",
        "### ‚≠ê To run the finetuned model like in a ChatGPT style interface, first click the **| >_ |** button.\n",
        "![](https://raw.githubusercontent.com/unslothai/unsloth/nightly/images/Where_Terminal.png)\n",
        "\n",
        "---\n",
        "---\n",
        "---\n",
        "\n",
        "### ‚≠ê Then, type `ollama run unsloth_model`\n",
        "\n",
        "![](https://raw.githubusercontent.com/unslothai/unsloth/nightly/images/Terminal_Type.png)\n",
        "\n",
        "---\n",
        "---\n",
        "---\n",
        "### ‚≠ê And you have a ChatGPT style assistant!\n",
        "\n",
        "### Type any question you like and press `ENTER`. If you want to exit, hit `CTRL + D`\n",
        "![](https://raw.githubusercontent.com/unslothai/unsloth/nightly/images/Assistant.png)You can also use the `model-unsloth.gguf` file or `model-unsloth-Q4_K_M.gguf` file in llama.cpp.\n",
        "\n",
        "And we're done! If you have any questions on Unsloth, we have a [Discord](https://discord.gg/unsloth) channel! If you find any bugs or want to keep updated with the latest LLM stuff, or need help, join projects etc, feel free to join our Discord!\n",
        "\n",
        "Some other links:\n",
        "1. Train your own reasoning model - Llama GRPO notebook [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.1_(8B)-GRPO.ipynb)\n",
        "2. Saving finetunes to Ollama. [Free notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb)\n",
        "3. Llama 3.2 Vision finetuning - Radiography use case. [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(11B)-Vision.ipynb)\n",
        "6. See notebooks for DPO, ORPO, Continued pretraining, conversational finetuning and more on our [documentation](https://docs.unsloth.ai/get-started/unsloth-notebooks)!\n",
        "\n",
        "<div class=\"align-center\">\n",
        "  <a href=\"https://unsloth.ai\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "  <a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord.png\" width=\"145\"></a>\n",
        "  <a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a>\n",
        "\n",
        "  Join Discord if you need help + ‚≠êÔ∏è <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ‚≠êÔ∏è\n",
        "\n",
        "  This notebook and all Unsloth notebooks are licensed [LGPL-3.0](https://github.com/unslothai/notebooks?tab=LGPL-3.0-1-ov-file#readme).\n",
        "</div>\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0d5da7e017424aa0b7ff0d40abad1ecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d15261428824594908bd697644d61ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62191c10c14c4728bf85a293d29d37ce",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ec56936c53984c85ade94df6ce443ad5",
            "value": "‚Äá52002/52002‚Äá[01:18&lt;00:00,‚Äá804.54‚Äáexamples/s]"
          }
        },
        "4c4bc99385eb49dd95ad4b740b949e55": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62191c10c14c4728bf85a293d29d37ce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f107e2a1d274a2f9bec4acce979d2da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9a39684291d4eb1b7312640feae1462": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f107e2a1d274a2f9bec4acce979d2da",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0d5da7e017424aa0b7ff0d40abad1ecc",
            "value": "Map‚Äá(num_proc=2):‚Äá100%"
          }
        },
        "b3a8a71922f341758e1adf0f951208bb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7435502d95f4355b37d2f3332b057f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c4bc99385eb49dd95ad4b740b949e55",
            "max": 52002,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f62d1a6521574459ae6fb1ebd71ad631",
            "value": 52002
          }
        },
        "dee51ee264e24b809be18f6d286ae874": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a9a39684291d4eb1b7312640feae1462",
              "IPY_MODEL_d7435502d95f4355b37d2f3332b057f1",
              "IPY_MODEL_2d15261428824594908bd697644d61ed"
            ],
            "layout": "IPY_MODEL_b3a8a71922f341758e1adf0f951208bb"
          }
        },
        "ec56936c53984c85ade94df6ce443ad5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f62d1a6521574459ae6fb1ebd71ad631": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "267067dafbe94dfdb8870dcfd5e41392": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dfb2b0760f9b4fed8a51e9d2ef159625",
              "IPY_MODEL_6764006aa85d4917af731d1353d92494",
              "IPY_MODEL_60ef556b4c7649999c72d428c3d7375c"
            ],
            "layout": "IPY_MODEL_52ac2792620543e2a26ee32e92666efc"
          }
        },
        "dfb2b0760f9b4fed8a51e9d2ef159625": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10543dd3a389472195b6ad38736d2ed5",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_036349c761f549fbb7ed672e86cc4d88",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "6764006aa85d4917af731d1353d92494": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb268e703a854e1bb2c8cfe8240e696c",
            "max": 5702746405,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_50518331691b42e88c03059d64e05b62",
            "value": 5702746405
          }
        },
        "60ef556b4c7649999c72d428c3d7375c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a35ba367c2c4edb88ee4e4d45072d94",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_de8db97cc3f842fc9c5082736d1c2771",
            "value": "‚Äá5.70G/5.70G‚Äá[01:06&lt;00:00,‚Äá100MB/s]"
          }
        },
        "52ac2792620543e2a26ee32e92666efc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10543dd3a389472195b6ad38736d2ed5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "036349c761f549fbb7ed672e86cc4d88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb268e703a854e1bb2c8cfe8240e696c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50518331691b42e88c03059d64e05b62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1a35ba367c2c4edb88ee4e4d45072d94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de8db97cc3f842fc9c5082736d1c2771": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87b012781037424db9b76d612b826308": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b5aa226f8d61498c90af693bb5319575",
              "IPY_MODEL_dd4f19f2091d4680ac0bab1480dfac06",
              "IPY_MODEL_d031c0d46b1c44158425a6f30c2220a4"
            ],
            "layout": "IPY_MODEL_348d31ea3d8248529447d98a7a970277"
          }
        },
        "b5aa226f8d61498c90af693bb5319575": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8888bfbd41b4b3289d4ea49c4aff06a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b8cbde4b97024b298975a26f07e81df5",
            "value": "generation_config.json:‚Äá100%"
          }
        },
        "dd4f19f2091d4680ac0bab1480dfac06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b595eecbbbc4c798885c2049485c0ef",
            "max": 198,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8576200b2f744525be14c81a3ef2860b",
            "value": 198
          }
        },
        "d031c0d46b1c44158425a6f30c2220a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b0df7467aa04a388a186a87e2de81a9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ecccac4498194d6295d10374ea4fab8e",
            "value": "‚Äá198/198‚Äá[00:00&lt;00:00,‚Äá20.0kB/s]"
          }
        },
        "348d31ea3d8248529447d98a7a970277": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8888bfbd41b4b3289d4ea49c4aff06a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8cbde4b97024b298975a26f07e81df5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b595eecbbbc4c798885c2049485c0ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8576200b2f744525be14c81a3ef2860b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4b0df7467aa04a388a186a87e2de81a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecccac4498194d6295d10374ea4fab8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bfe1b2eeb0c94094a7c4336dcc31716a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fea0aa5bcba34af69a533b476613f4ef",
              "IPY_MODEL_83d8ae3a10774f9383dce13834fa6810",
              "IPY_MODEL_29232f5187534e71bc140ae2239500e5"
            ],
            "layout": "IPY_MODEL_ce353e3f5c5d44ccb4bb1887bb7dad86"
          }
        },
        "fea0aa5bcba34af69a533b476613f4ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72f81401952143509e6ddb44e9aa64bb",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5bfa027a7f0b421ab63cd299752fd751",
            "value": "tokenizer_config.json:‚Äá"
          }
        },
        "83d8ae3a10774f9383dce13834fa6810": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bad196e64e514f178e8b4474493cfbaf",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51c60bb5725c48ef9ba686252c4dc9e6",
            "value": 1
          }
        },
        "29232f5187534e71bc140ae2239500e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f542ad4b8cb14743b1ccaea4aea03821",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8c8077d5bb48489caa6256e17941d7d6",
            "value": "‚Äá50.6k/?‚Äá[00:00&lt;00:00,‚Äá4.31MB/s]"
          }
        },
        "ce353e3f5c5d44ccb4bb1887bb7dad86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72f81401952143509e6ddb44e9aa64bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bfa027a7f0b421ab63cd299752fd751": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bad196e64e514f178e8b4474493cfbaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "51c60bb5725c48ef9ba686252c4dc9e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f542ad4b8cb14743b1ccaea4aea03821": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c8077d5bb48489caa6256e17941d7d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "575c04d7da794dbaa0b68b56a07c78cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_261cd71c6bc840cfb5a1ebf38f9ad221",
              "IPY_MODEL_7bb5fe9df041437e80042a27a269ed70",
              "IPY_MODEL_ce6355ed0b1548a288d072faa44e2978"
            ],
            "layout": "IPY_MODEL_0705a74711a14023a78f855c5df606c1"
          }
        },
        "261cd71c6bc840cfb5a1ebf38f9ad221": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce0d31a6c95e4d9dbf11fbd1272973ef",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c00ea326da08481788558fb3fa00f166",
            "value": "tokenizer.json:‚Äá"
          }
        },
        "7bb5fe9df041437e80042a27a269ed70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0618c6fcf8b247beb56b3e0904f1afee",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_923b54e5354d4813a51b6072ab2b64e7",
            "value": 1
          }
        },
        "ce6355ed0b1548a288d072faa44e2978": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84a68f8831294380ad61ec2a6aba4717",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b15dc6ee8ab14be1952d2c3663a1108f",
            "value": "‚Äá9.09M/?‚Äá[00:00&lt;00:00,‚Äá121MB/s]"
          }
        },
        "0705a74711a14023a78f855c5df606c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce0d31a6c95e4d9dbf11fbd1272973ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c00ea326da08481788558fb3fa00f166": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0618c6fcf8b247beb56b3e0904f1afee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "923b54e5354d4813a51b6072ab2b64e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "84a68f8831294380ad61ec2a6aba4717": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b15dc6ee8ab14be1952d2c3663a1108f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c4254c725c34168a182a063155033fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df89b85749974042bbe1de973e6653ee",
              "IPY_MODEL_77b11be9dfa84d08bb120ed7cfe1f53c",
              "IPY_MODEL_cd6060fbdd784c55bc4b1e956b5f36d3"
            ],
            "layout": "IPY_MODEL_b7b6b9faa9cf49ca96a06e30b583daee"
          }
        },
        "df89b85749974042bbe1de973e6653ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da60b444b0dd4fe6ae76b73bd790f751",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a8129fe72d384c53b900474f33914275",
            "value": "special_tokens_map.json:‚Äá100%"
          }
        },
        "77b11be9dfa84d08bb120ed7cfe1f53c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5a209fbc30b44f0a377f858130c52db",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d85ba7cb2c964dafbc54fbc1090da824",
            "value": 350
          }
        },
        "cd6060fbdd784c55bc4b1e956b5f36d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da1bf2f2a93847308701555f0cab7aa2",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_022bb664096d4bd29db4d4ebfe0472f6",
            "value": "‚Äá350/350‚Äá[00:00&lt;00:00,‚Äá26.2kB/s]"
          }
        },
        "b7b6b9faa9cf49ca96a06e30b583daee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da60b444b0dd4fe6ae76b73bd790f751": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8129fe72d384c53b900474f33914275": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5a209fbc30b44f0a377f858130c52db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d85ba7cb2c964dafbc54fbc1090da824": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "da1bf2f2a93847308701555f0cab7aa2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "022bb664096d4bd29db4d4ebfe0472f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ee5b91602d74aee9448bf9ce042eb1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab5399b2268e44a9a2f49786fabbfaad",
              "IPY_MODEL_a9854cafd27740d69fd45a8248304d71",
              "IPY_MODEL_3738f99efac6430ca65694f6c0977ff4"
            ],
            "layout": "IPY_MODEL_93d6a2fd944b4efbac603a7800f38122"
          }
        },
        "ab5399b2268e44a9a2f49786fabbfaad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76400998973d4ea08bc0e99ecc45869e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8179590eb74148cd88ef441d783b0141",
            "value": "Generating‚Äátrain‚Äásplit:‚Äá"
          }
        },
        "a9854cafd27740d69fd45a8248304d71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11caea6e2c504bf882e896ed6dbbf810",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b7bd5c149ee40c1895a7cd7020304f1",
            "value": 1
          }
        },
        "3738f99efac6430ca65694f6c0977ff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2af37c7f26a24263b40af49ae782d39d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e584bceda9fc434589f08fde08c85e08",
            "value": "‚Äá7921/0‚Äá[00:00&lt;00:00,‚Äá11882.48‚Äáexamples/s]"
          }
        },
        "93d6a2fd944b4efbac603a7800f38122": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76400998973d4ea08bc0e99ecc45869e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8179590eb74148cd88ef441d783b0141": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11caea6e2c504bf882e896ed6dbbf810": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "7b7bd5c149ee40c1895a7cd7020304f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2af37c7f26a24263b40af49ae782d39d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e584bceda9fc434589f08fde08c85e08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "380fa4b4dd704501a9a9ccee27665264": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_74db0395e57a4ab5b174996cedec8f10",
              "IPY_MODEL_56395422789d4b60833457ebe04e8478",
              "IPY_MODEL_e75fa6966dff485c8f32fe9f87845e0f"
            ],
            "layout": "IPY_MODEL_ce133f5daa0b4f44aa64f17339ac59f4"
          }
        },
        "74db0395e57a4ab5b174996cedec8f10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07bee94acc934e818b3820b7cc70665f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a3409eb0f9ea4859b3f26474d5993a49",
            "value": "Unsloth:‚ÄáStandardizing‚Äáformats‚Äá(num_proc=2):‚Äá100%"
          }
        },
        "56395422789d4b60833457ebe04e8478": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bd0cc936da741a6985adbac6c96ffe7",
            "max": 7921,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8308a4c3ff3142098c32e989ea1c450e",
            "value": 7921
          }
        },
        "e75fa6966dff485c8f32fe9f87845e0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b0488359d994f0a919368035bd814c9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_01fcf5ebde8048478df5c22f3d2f6193",
            "value": "‚Äá7921/7921‚Äá[00:00&lt;00:00,‚Äá12087.54‚Äáexamples/s]"
          }
        },
        "ce133f5daa0b4f44aa64f17339ac59f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07bee94acc934e818b3820b7cc70665f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3409eb0f9ea4859b3f26474d5993a49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4bd0cc936da741a6985adbac6c96ffe7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8308a4c3ff3142098c32e989ea1c450e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b0488359d994f0a919368035bd814c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01fcf5ebde8048478df5c22f3d2f6193": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9644fafe8d5a4c3cafdfed531342446c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fb1eb289f8df4ddeaf1f3be63ad269a0",
              "IPY_MODEL_790d391e7b124d2ab9a2351f8112f1ed",
              "IPY_MODEL_eaa6131e2eda41958d46e1a1d179c13d"
            ],
            "layout": "IPY_MODEL_75345f0b396347e680b828c9c12bbdf7"
          }
        },
        "fb1eb289f8df4ddeaf1f3be63ad269a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad9afe9bcddc412286f72408819be170",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_dc7cb15cef5949b881a157df26e043b3",
            "value": "Map:‚Äá100%"
          }
        },
        "790d391e7b124d2ab9a2351f8112f1ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cc7a84ba4e04542bf8b47a72ad4ba72",
            "max": 7921,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b15fe2c101004aa3b25500c227d0f000",
            "value": 7921
          }
        },
        "eaa6131e2eda41958d46e1a1d179c13d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23be1252a7ca4831ab5c65fcdc7ad9a7",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_331d163fa49b4d87b843419d27c02d85",
            "value": "‚Äá7921/7921‚Äá[00:01&lt;00:00,‚Äá4666.01‚Äáexamples/s]"
          }
        },
        "75345f0b396347e680b828c9c12bbdf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad9afe9bcddc412286f72408819be170": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc7cb15cef5949b881a157df26e043b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3cc7a84ba4e04542bf8b47a72ad4ba72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b15fe2c101004aa3b25500c227d0f000": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "23be1252a7ca4831ab5c65fcdc7ad9a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "331d163fa49b4d87b843419d27c02d85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b58a2542ca740bb9de91737e72bac3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d30ba03bb4c4b3bb1e1b972b017c353",
              "IPY_MODEL_574c5b3155034fcf90cb798f96ab3a7f",
              "IPY_MODEL_319e1444938247239486ac86f2b454fb"
            ],
            "layout": "IPY_MODEL_8762f1b75f02443db75f29c06ed08b80"
          }
        },
        "0d30ba03bb4c4b3bb1e1b972b017c353": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f79e27de9034321a29706c0915c6ef2",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7db6014c1ce847808dbffd34a86144c7",
            "value": "Unsloth:‚ÄáTokenizing‚Äá[&quot;text&quot;]‚Äá(num_proc=6):‚Äá100%"
          }
        },
        "574c5b3155034fcf90cb798f96ab3a7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eccb322f704844df85026fdba73e9d30",
            "max": 7921,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1cc5c69f172149d1a1e16eee024b8d72",
            "value": 7921
          }
        },
        "319e1444938247239486ac86f2b454fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_709c8c84bb894d9881319f7c479ff735",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f2d51fd8d989464aa30fe9f66947034b",
            "value": "‚Äá7921/7921‚Äá[00:18&lt;00:00,‚Äá924.43‚Äáexamples/s]"
          }
        },
        "8762f1b75f02443db75f29c06ed08b80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f79e27de9034321a29706c0915c6ef2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7db6014c1ce847808dbffd34a86144c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eccb322f704844df85026fdba73e9d30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cc5c69f172149d1a1e16eee024b8d72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "709c8c84bb894d9881319f7c479ff735": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2d51fd8d989464aa30fe9f66947034b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4da576b5c78d4098ab1ee9779394d856": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bf390d8bf4df447787c94e74ee0db8fb",
              "IPY_MODEL_355d5195566d4b61b4156de40149633d",
              "IPY_MODEL_f4dcd0789eae4fe182d5a2dd7557b029"
            ],
            "layout": "IPY_MODEL_e55f71f67f564bf795db57edbbb81632"
          }
        },
        "bf390d8bf4df447787c94e74ee0db8fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc924ef5b998460b83c80e291b5abf17",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_1005790d601346ea964e002e36d8d5a2",
            "value": "Map:‚Äá‚Äá‚Äá0%"
          }
        },
        "355d5195566d4b61b4156de40149633d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10c7b90b26b94c8ea545031259653f8c",
            "max": 7921,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5381ef010c1040ebb0d633903af0ccc9",
            "value": 0
          }
        },
        "f4dcd0789eae4fe182d5a2dd7557b029": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe53dc5367f94c1db0ba92cafa7d78a1",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3533c249ab484b5b939f017e32fc8069",
            "value": "‚Äá0/7921‚Äá[00:00&lt;?,‚Äá?‚Äáexamples/s]"
          }
        },
        "e55f71f67f564bf795db57edbbb81632": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc924ef5b998460b83c80e291b5abf17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1005790d601346ea964e002e36d8d5a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10c7b90b26b94c8ea545031259653f8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5381ef010c1040ebb0d633903af0ccc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe53dc5367f94c1db0ba92cafa7d78a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3533c249ab484b5b939f017e32fc8069": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}